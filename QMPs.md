# Questionable Measurement Practices
Eiko Fried and Jessica Flake

## [Resources](https://docs.google.com/document/d/16xDCPQiP82Bp-Z8Eda3s9jv7_CzqNOJzRueS7RJvaJ8/edit)

## [Measurement Primer](https://docs.google.com/document/d/11jyoXtO0m2lUywpC04KjLvI5QcBUY4YtwEvw6cg2cMs/edit)

- Quality of theory is related to how good measurement is and if the theory is good but measurement is bad theory will be incorrectly updated
- Measurement is more than questionnaires  but the focus of this session is questionnaires
- Focus will be on transparency in measurement process. pre-registration is difficult as the decisions are very iterative. Have to make measurement decisions that you don’t know you will have to make
	- So declare decisions are you make them. Each instrument as unforeseen decisons that need to be made post-hoc
- In JPSP 700 measures in 35 articles and most were item based scales. 30% of those were one item scales
	- 40% of measures not cited
	- 19% were modified/adapted
	- Not uncommon to not find a scale development paper.
	- Precedent scales are scales with no shown validity but the scale has become widely used
	- Majority of scales only have reliability (alpha)
	- 18% will have no other information
	- 21% will report more, i.e. factor analysis
- Chronbach’s alpha assumes scale is uni-deminsional, it does not show uni-dimensionality
	- is often used to signal validity in studies where no validation study is cited
-  Measurement variability makes replication studies hard to interpret
- In replication studies we are interesting in the validity of findings and conclusions
	- measurement is a low level decision which influences the statistics which influences the conclusions
- QRP is exploiting ambiguity to get the result you want
	- the asks you to question intention of the intentions of the researcher
	- perhaps better to say questionable reporting practices, which removes the intention aspect of the judgement
- Flake & Fried take questionable reporting practices approach. Accepts we do not know the intention of the researcher, can easily be unintentional

## Questionable Measurement Practices (QMP)
- decision a researcher make that leave questions about the measurement practices in the study
- QMPs lack justification and transparency
	- It’s ok to say we made it up on the fly, we did it for this reasons and call it a limitation
- QMP is not evidence for p-hacking, it just means we do not know how decisions were made
- QMPs make it very hard to reproduce and replicate a study
- Hans IJzerman has detailed study measurement and pre-reg stuff on his (OSF)[https://osf.io/3hsfj/] page
- Garden of forking measurement paths in which different measurement decisions will lead to changes in inferential test results

## Eiko wants to study depression....
### Measurement Selection
#### Crowdsource input
- cost
- construct definition
- scale length
- face validity
- readability / usability
- validation sample
- To select a measure as yourself
	1. what is my theory about the construct, how does the measure relate
	2. what measures exist
	3. Do they cover the content
	4. Are the psychometrics/evidence good

#### Eiko Input
1. What is our theory of depression, how does our measure relate to depression, i.e. is it continuous or categorical
	- A-priori decision = categorical
	- a-priori justification is because depression is a brain disorder that cause symptoms
	- theory informs how you want to model the measurements
	- A lack of plan here would allow for QMPs
2. What do the measures cover as far as item content goes
	- Scales differ from each other even when they measure the same thing
	- Decision is to take two scales based on two different theories of depression
	- one is stated as the primary scale
4. What is the validity evidence for each scale - see Flake 2017 paper (in slides)

#### Summary
- choose measures that align with theory
- select instrument with content and other validity evidence. Face validity also matters in the context of understanding what aspects of the construct the scale measures
- report the decisions and their justification
	- the justification can be weak for whichever reason

#### Common measurement selection QRPs
- mismatch with theory and measurement
- multiple measures of the same construct with the different content (jingle) and multiple measures of different constructs with same content
- measures have no previous validity evidence or source
- selective reporting
- If you justify decisions you can avoid QMPs about selection

## In My Work
```
Construct = Alexithymia
Multiple Measures = Yes;
				Toronto Alexithymia Scale
				Bermnond Vorst Alexithymia questionnaire
				Perth Alexithymia questionnaire
How are the selected = Sometimes theory (if looking at type 1 or type 2) but generally the TAS is selected out of prominence. Perth questionnaire is new and I don't think it has been used yet but was developed out of theory.
Primary weight: What most people use in the literature
```
### Measurement Use
#### Many decisions
- Have to decide how to present them and how to analyse them
1. What is the response format (items, scale points)
	- the same scale has differnet measurement styles so have to choose the best one according to theory
2. How do you score the measure (mean, sum, latent factor, etc. removal of items without variance, subscales or not)
3. How many scores will the measure have (unitary construct, multiple factors etc.)
4. Multiple Scales
	- are all scales going to be reported (yes)
	- exclusion criteria, only report above alpha of .6

#### Common QMPs
- unclear reporting of response scale or scoring
- no justification for subscale creation
- across a set of studies look at changes in scales
- Ask: would someone be able to read this and exactly reproduce my study

### Measurement Modification
1. Should measures be combined?
	- Assume scales were not planned to be combined unless otherwise stated. Although best to clearly state this
2. Should I break measures apart?
	- If structure is not anticipated then make statement about registered plan but then go with the two structures
3. Should I add or remove items?
	- might remove one with no variability and one with no good properties
	- then no to register this decision treee next time
4. Should I change item wording?
	- give all items exactly

#### Common QMPs
- item removal
- combining scales
- breaking scales apart
- cherry picking items/analysis
- going back and forth between single and multiple item analyses
- watch for 'adapted' etc. make sure you get the validity evidence or at least item wording.

It's ok to modify scales but it is essential to be transparent about this 
